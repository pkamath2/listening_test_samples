<script src="https://assets.crowd.aws/crowd-html-elements.js"></script>
<style>
    .clipbox {
        border: solid black 1px;
        margin: 30px;
        padding: 10px;
        width: 30%;
    }

    .clipbox-noborder {
        margin-left: 10px;
        padding: 10px;
        width: 70%;
    }

    .clipbox-border {
        margin-left: 2%;
        border: solid black 1px;
        padding: 2px;
        width: 70%;
    }

    .pad-top {
        padding-top: 20px;
        padding-bottom: 20px;
        margin-left: 2%;
        width: 70%;
    }

    .margin-top {
        margin-top: 20px;
    }

    h3 {
        margin-top: 0;
    }

    .left {
        width: 100%;
        display: inline-block;
    }

    .references-section {
        display: grid;
        grid-template-columns: 30% 30% 40%;
        padding-bottom: 30px;
    }

    .clips-section {
        display: grid;
        grid-template-columns: 5% 30% 40%;
        padding-left: 10px;
    }

    .clips-section span {
        padding-top: 20px;
    }

    .right {
        width: 50%;
        display: inline-block;
    }

    /* The Modal (background) */
    .modal {
        display: none;
        /* Hidden by default */
        position: fixed;
        /* Stay in place */
        z-index: 1;
        /* Sit on top */
        left: 0;
        top: 0;
        width: 100%;
        /* Full width */
        height: 100%;
        /* Full height */
        overflow: auto;
        /* Enable scroll if needed */
        background-color: rgb(0, 0, 0);
        /* Fallback color */
        background-color: rgba(0, 0, 0, 0.4);
        /* Black w/ opacity */
    }

    /* Modal Content/Box */
    .modal-content {
        background-color: #fefefe;
        margin: 15% auto;
        /* 15% from the top and centered */
        padding: 20px;
        border: 1px solid #888;
        width: 33%;
        /* Could be more or less, depending on screen size */
    }

    /* The Close Button */
    .close {
        color: #aaa;
        float: right;
        font-size: 28px;
        font-weight: bold;
    }

    .close:hover,
    .close:focus {
        color: black;
        text-decoration: none;
        cursor: pointer;
    }
</style>

<script>
    function listenedCheck(elementName) {
        var x = document.getElementById(elementName);
        x.value = 'Yes'
    }

    function validateForm() {
        firstListenedCheck = document.getElementById('first_sound_listened_test').value;
        secondListenedCheck = document.getElementById('second_sound_listened_test').value;

        betterClip = document.getElementsByName('better_clip');
        atleastOneSelected = false
        for (i = 0; i < betterClip.length; i++) {
            atleastOneSelected = atleastOneSelected || betterClip[i].checked
        }

        if (firstListenedCheck == 'Yes' && secondListenedCheck == 'Yes' && atleastOneSelected) {
            return true;
        } else {
            return false;
        }


    }
</script>
<crowd-form>
    <crowd-instructions link-text="View instructions" link-type="button">
        <short-summary>
            <p>Note: Please ‘accept’ this HIT only if you have access to a laptop or desktop with internal or external
                speakers or headphones and if you are using Chrome or Firefox browser. This HIT involves listening and
                evaluating audio clips.</p>
            <h3>Project Details:</h3>
            <p>The purpose of this research is to evaluate the quality of synthetic audio clips generated using an
                artificial neural network. The audio clips under test belong to the domain of audio textures (for e.g. a
                series of popping sounds, the ticking sound made by a Geiger counter or the sound made by water filling
                a container) or pitches made by musical instruments. The specific goal of this project is to ensure that
                the synthetic outputs generated by these deep learning models are validated by human beings to test for
                certain sound qualities like smoothness, naturalness or absence of noise etc.</p>

            <h3>Consent:</h3>
            <p>Before working on this HIT, please read the consent details on the 'View Consent Details' section of the
                HIT page.
                By accepting this HIT on Mechanical Turk, you will be indicating your consent to
                participating in our study
                as per the details outlined the consent details section.
            </p>

            <br />
            <h3>Task Instructions:</h3>
            <p>In this task you will be presented with two audio clips. While both clips start at one sound (like
                sound of fire cracking or sound of an engine running) and end at another sound (like sound of an
                appluase from a crowd or sound of water filling a container), they use two different
                algorithms to build the transition from the starting sound (fire crackling/engine running) to its ending
                (crowd/water filling a container).</p>
            <p>Although both clips may sound quite different from each other, you will need to select the clip which
                sounds more 'smooth' in quality while transitioning from starting to its ending.</p>
            <p>After you finish selecting an option you will need to submit the HIT.</p>
            <br />
            <br />
            <h3>For any questions:</h3>
            <p>Please use the ‘Contact this requester’ link on the HIT details if you need further details or
                clarifications on the task. The Principal Investigator (the person in charge of this research) or
                his/her
                representative will describe this research to you and answer all of your questions. <br />
                Note: On using this
                feature, your e-mail address and your name will automatically be visible to our research team so that we
                can reply to you.
            </p>
        </short-summary>

        <detailed-instructions>
            <p>Please see summary tab for all instructions.</p>
        </detailed-instructions>


    </crowd-instructions>

    <crowd-modal link-text="View Consent Details" link-type="button">
        <div id="container" class="container">
            <div>
                <table>

                    <tr>
                        <td style="padding-left: 1%;width:10%"><img
                                src='https://animatedsound.com/amt/ui/NUS_logo_full-vertical.jpg' width="75%"></td>
                        <td>
                            <h3>Welcome to the qualitative evaluation of
                                artificially synthesized audio clips using deep neural networks&nbsp;&nbsp;</h3>

                        </td>
                    </tr>
                </table>
            </div>

            <div>

                <p><span style="font-family:Tahoma,Geneva,sans-serif;">Thank you for your interest in this audio
                        evaluation
                        task on Mechanical Turk. This page outlines the details with respect to your consent to
                        participate in our study.</span></p>
                <p><br>
                    <span style="font-family:Tahoma,Geneva,sans-serif;"><u><strong>Protocol Title:</strong></u><br>
                        Qualitative evaluation of artificially synthesized audio clips synthesized using
                        deep neural networks</span>
                </p>

                <p><br>
                    <span style="font-family:Tahoma,Geneva,sans-serif;"><u><strong>Purpose of this
                                research:</strong></u><br>
                        The purpose of this research is to evaluate the quality of synthetic audio clips
                        generated using an artificial neural network. The audio clips under test belong to
                        the domain of audio textures (for e.g. a series of popping sounds, the ticking
                        sound made by a Geiger counter or the sound made by water filling a container) or pitches made
                        by musical instruments. The specific goal of this project is to ensure that the synthetic
                        outputs generated
                        by these deep learning models are validated by human beings to test for certain
                        sound qualities like smoothness, naturalness or absence of noise etc.</span>
                </p>

                <p><br>
                    <span style="font-family:Tahoma,Geneva,sans-serif;"><u><strong>Contacting Us:</strong></u><br>
                        Please use the ‘Contact this requester’ link on the Mechanical Turk's HIT details
                        section if you need further details or clarifications on the task. The Principal
                        Investigator (the person in charge of this research) or his/her representative will
                        answer all of your questions.
                        Note: On using this feature, your e-mail address and your name will
                        automatically be visible to our research team so that we can reply to you.</span>
                </p>


                <p><br>
                    <span style="font-family:Tahoma,Geneva,sans-serif;"><u><strong>Your personal data:</strong></u><br>
                        Only the principal investigator and his/her representative has your worker ID and this will not
                        be
                        released to any other person. We will <u><strong>NOT</strong></u> request Amazon Mechanical Turk
                        for
                        your person identifying details. Also, this worker ID data will not be used in a publication or
                        presentation. We will use this worker ID only for the purposes of correlating consent to HIT
                        responses and distributing compensation via Mechanical Turk.<o:p></o:p></span>
                </p>

                <p><span style="font-family:Tahoma,Geneva,sans-serif;">All data collected will be kept in accordance to
                        the
                        National University of Singapore’s Research Data Management Policy. Research data used in any
                        publication will be kept for a minimum of 10 years before being discarded.<o:p></o:p></span></p>
            </div>

            <div><br>
                <span style="font-family:Tahoma,Geneva,sans-serif;">By accepting the HIT on Amazon's Mechanical Turk,
                    you
                    acknowledge that - </span>
            </div>

            <ol>
                <li><span style="font-family:Tahoma,Geneva,sans-serif;">You have agreed to take part in
                        this&nbsp;research.</span></li>
                <li><span style="font-family:Tahoma,Geneva,sans-serif;">You have read the instructions on the mechanical
                        turk website and details on this form which explains the use of the data you submit for this
                        research.</span></li>
                <li><span style="font-family:Tahoma,Geneva,sans-serif;">You can withdraw from this research at any point
                        of
                        time. If you want the data you already submitted to be deleted you will&nbsp;inform the
                        Principal
                        Investigator and all your data will be discarded.</span></li>
                <li><span style="font-family:Tahoma,Geneva,sans-serif;">You will not have any financial benefits that
                        result
                        from the commercial development of this research.</span></li>
                <li><span style="font-family:Tahoma,Geneva,sans-serif;">You agree to be re-contacted for future related
                        studies via&nbsp;Amazon's Mechanical Turk website. You understand that future studies will be
                        subject to an Institutional Review Board's approval.&nbsp;<span lang="EN-US">
                            <o:p></o:p>
                        </span></span></li>
            </ol>

            <div>&nbsp;</div>


        </div>
    </crowd-modal>
    <div id="errorModal" class="modal">

        <!-- Modal content -->
        <div class="modal-content">
            <span class="close">&times;</span>
            <p>Please listen to all sound clips <b>fully</b> and select atleast one option before submitting the task.
            </p>
        </div>

    </div>
    <div class="container">
        <input type="hidden" value="No" name="first_sound_listened_test" id="first_sound_listened_test" />
        <input type="hidden" value="No" name="second_sound_listened_test" id="second_sound_listened_test" />

        <input type="hidden" value="${type_under_test}" name="type_under_test" id="type_under_test" />
        <!--nsynth or oreilly-->

        <input type="hidden" value="${first_clip_type}" name="first_clip_type" id="first_clip_type" />
        <!-- 'gan' or 'gan_remapped'. If this is gan, the other should be gan_remapped-->
        <input type="hidden" value="${second_clip_type}" name="second_clip_type" id="second_clip_type" />
        <!-- 'gan' or 'gan_remapped'. If this is gan, the other should be gan_remapped-->


        <div class="clipbox-border margin-top">
            <p style="padding-left: 10px;"> Please read the instructions by clicking on 'View Instructions' and details
                regarding your consent by clicking on 'View Consent Details'. <br />By accepting this HIT, you agree to
                the terms of this study outlined
                in the 'View Consent Details' section</p>
        </div>

        <div class="clipbox-noborder">
            <p style="padding-left: 10px;"><b><u>Audio Smoothness Test</u></b></p>

            <p style="padding-left: 10px;"> This page outlines 2 audio clips. Both clips start at one sound (e.g., sound
                of fire crackling or an engine running) and slowly transitions towards the end to another sound
                (e.g., sound made by a large crowd or sound made by water filling a container) by using two different
                algorithms.
            </p>

            <p style="padding-left: 10px;">Please select which audio clip is <u><b>more smooth</b></u> in quality while
                transitioning from the start of the clip to its end, in comparison to the
                other</b></u>.</p>


        </div>
        <div class="clipbox-noborder">

            <div class="clips-section">
                <span style="align-items: center;">Clip 1:</span>
                <span style="align-items: center;"><audio controls=""
                        onended="listenedCheck('first_sound_listened_test')">
                        <!-- <source
                        src="combined_clips/oreilly-gan-pinned-test_spectset2snd_d1.0_0_1_2_3_4_5_6_7_8_9_10_11_12_13_14_15_16_17_18_19.wav"
                        src="${audio_url_1}"
                        type="audio/wav" /> -->
                        <source src="${audio_url_1}" type="audio/wav" />
                    </audio></span>
            </div>
            <div class="right">
                <br />
            </div>
            <div class="clips-section">
                <span style="align-items: center;">Clip 2:</span>
                <span style="align-items: center;"><audio controls=""
                        onended="listenedCheck('second_sound_listened_test')">
                        <source src="${audio_url_2}" type="audio/wav" />
                    </audio></span>
            </div>

            <div class="right">
            </div>
        </div>

        <div class="pad-top">
            <crowd-radio-group>
                <input type="radio" name="better_clip" id="first_clip_better" value="first_clip_better"><label
                    for="first_clip_better">Clip 1 is more smooth than clip 2</label><br /><br />
                <input type="radio" name="better_clip" id="second_clip_better" value="second_clip_better"><label
                    for="second_clip_better">Clip 2 is more smooth than clip 1</label><br /><br />
                <input type="radio" name="better_clip" id="both_similar" value="both_similar"><label
                    for="both_similar">Cannot compare or No noticeable difference between the two
                    clips</label>
            </crowd-radio-group>
        </div>

        <p style="padding-left: 10px;"><i>Listen to all sound clips fully on this page before submitting your
                response.</i></p>
</crowd-form>
</div>
</div>
</crowd-form>
<script>
    var modal = document.getElementById("errorModal");
    var span = document.getElementsByClassName("close")[0];
    span.onclick = function () {
        modal.style.display = "none";
    }
    document.querySelector('crowd-form').onsubmit = function (e) {
        if (!validateForm()) {
            e.preventDefault();
            modal.style.display = "block";
        }
    }
    window.onclick = function (event) {
        if (event.target == modal) {
            modal.style.display = "none";
        }
    }
</script>